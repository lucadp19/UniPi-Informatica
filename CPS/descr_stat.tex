\chapter{Statistica descrittiva}

\section{Concetti base}

La statistica descrittiva è la branca della statistica che descrive fenomeni statistici senza sfruttare nozioni di probabilità. I concetti fondamentali della statistica descrittiva sono il concetto di \emph{popolazione} e di \emph{campione}: la popolazione è l'insieme delle entità e dei dati che vogliamo studiare, mentre il campione è un piccolo sottoinsieme della popolazione che verrà analizzato per fini statistici.

Altri concetti base sono il concetto di \emph{frequenza assoluta} e \emph{relativa}: si dice frequenza assoluta di un evento $A$ il numero di volte che l'evento accade, senza considerare il numero di eventi (anche di tipo diverso) che accadono; invece si dice frequenza assoluta di un evento $A$ il numero di volte che l'evento accade diviso il numero di eventi totali.

\section{Analisi numerica dei dati}

Supponiamo di avere un vettore $\vec{x} = (x_1, \dots, x_n) \in \R^n$ che rappresenta i nostri dati. Possiamo definire alcune operazioni fondamentali su questi dati.

\begin{definition}
    [Media (empirica)] Dato $\vec x$ vettore di dati, si dice \emph{media (empirica)} il valore \begin{equation}
        \mean{x} \deq \frac{1}{n}\sum_{i=1}^n x_i = \frac{x_1 + \dots + x_n}{n}.
    \end{equation}
\end{definition}

Per descrivere quanto i dati contenuti in $\vec x$ si discostano dalla media $\mean x$ si usa il concetto di varianza:
\begin{definition}
    [Varianza] Dato $\vec x$ vettore di dati, si dice \emph{varianza campionaria} il valore \begin{equation}
        \var{\vec x} \deq \sum_{i=1}^n \frac{(x_i - \mean x)^2}{n-1};
    \end{equation} si dice invece \emph{varianza empirica} il valore \begin{equation}
        \var*{\vec x} \deq \sum_{i=1}^n \frac{(x_i - \mean x)^2}{n}.
    \end{equation}
\end{definition}

La varianza campionaria verrà usata quando i dati si riferiscono ad un campione, mentre la varianza empirica sarà più utile per trattare dati riferiti alle popolazioni.

In alcuni casi è utile conoscere la radice quadrata della varianza, quindi definiamo lo \emph{scarto quadratico medio} (o \emph{deviazione standard}) nel seguente modo: \begin{equation}
    \sd{\vec x} \deq \sqrt{\var{\vec x}}, \quad \sd*{\vec x} \deq \sqrt{\var*{\vec x}}.
\end{equation}

\begin{proposition}
    Vale la seguente uguaglianza: \begin{equation} \label{eq:uguaglianza_base}
        \sum_{i=1}^n (x_i - \mean x)^2 = \sum_{i=1}^n x_i^2 - n\mean{x}^2.
    \end{equation}
\end{proposition}
\begin{proof}
    \begin{align*}
        \sum_{i=1}^n (x_i - \mean x)^2 &= \sum_{i=1}^n (x_i^2 - 2x_i\mean x + \mean{x}^2)\\
        &= \sum_{i=1}^n x_i^2 - 2\mean x\sum_{i=1}^n x_i + \sum_{i=1}^n \mean{x}^2\\
        &= \sum_{i=1}^n x_i^2 - 2\mean x\sum_{i=1}^n x_i + n\mean{x}^2\\
        \intertext{Ricordando che $\mean x = \frac1n \sum_{i=1}^n x_i$, ovvero $\sum_{i=1}^n x_i = 2\mean x$:}
        &= \sum_{i=1}^n x_i^2 - 2n\mean{x}^2 + n\mean{x}^2\\
        &= \sum_{i=1}^n x_i^2 - n\mean{x}^2. \qedhere
    \end{align*}
\end{proof}

Usando la \eqref{eq:uguaglianza_base} otteniamo che \[
    \var*{\vec x} = \sum_{i=1}^n \frac{x_i^2}{n} - \mean x^2.
\]

\begin{proposition}
    Dato $\vec x$ vettore dei dati, la varianza (campionaria o empirica) di $\vec x$ è $0$ se e solo se \[
        x_1 = \dots = x_n = \mean x.    
    \]
\end{proposition}
La dimostrazione è ovvia: essendo la varianza definita come la somma di termini non negativi, essa è uguale a $0$ se e soltanto se ogni termine è uguale a $0$, ovvero se e solo se $x_i = \mean x$ per ogni $i = 1, \dots, n$. La varianza quindi rappresenta la "dispersione" dei dati: più è alta, più i dati sono diversi tra loro; più è bassa e più sono vicini (nel caso limite in cui sono tutti uguali la varianza è $0$).

Possiamo generalizzare questa idea: fissata una soglia $d \in \R$ consideriamo il numero di elementi $x_i$ la cui distanza dalla media $\mean x$ è maggiore o uguale a $d$: \[
    \#\set{x_1 \suchthat \abs*{x_i - \mean x} \geq d}.
\] È possibile dimostrare che vale la seguente disuguaglianza: \[
    \#\set{x_1 \suchthat \abs*{x_i - \mean x} \geq d} \leq \frac{1}{d}\sum_{i=1}^n (x_i - \mean x)^2,
\] da cui, dividendo entrambi i membri per $n$, segue un caso particolare della cosiddetta \emph{disuguaglianza di Chebyshev}: \begin{equation}
    \frac{\#\set{x_1 \suchthat \abs*{x_i - \mean x} \geq d}}{n} \leq \frac{\var*{\vec x}}{d}.
\end{equation} Il membro sinistro rappresenta la \emph{percentuale} dei dati che si discostano dalla media per un valore superiore alla soglia $d$.

Un altro metodo utile per ripartire i dati è utilizzare la cosiddetta \emph{funzione di ripartizione empirica}.
\begin{definition}
    Dato $\vec{x} \in \R^n$ vettore dei dati, la funzione di ripartizione empirica è una funzione $F_e : \R \to [0,1]$ tale che \begin{equation*}
        F_e(t) = \frac{\#\set{x_i \suchthat x_i \leq t}}{n}.
    \end{equation*}
\end{definition}
Dunque per ogni soglia $t$ la funzione di ripartizione empirica restituisce la percentuale dei dati che sono minori o uguali a $t$.

\begin{example}
    Se il vettore dei dati è $\vec x = (1.2, -0.7, 3.4, 1.6, 2.1)$ per trovare la funzione di ripartizione empirica $F_e$ mi conviene innanzitutto ordinarli, ottenendo \[
        \vec x = (-0.7, 1.2, 1.6, 2.1, 3.4).    
    \] A questo punto posso descrivere molto semplicemente la funzione di ripartizione empirica:
    \begin{itemize}
        \item se $t < -0.7$ allora $F_e(t) = 0$: tutti i dati sono maggiori della soglia $t$;
        \item se $t \in \halfCloseInt{-0.7, 1.2}$ allora $F_e(t) = \nicefrac{1}{5}$: un solo dato è sicuramente minore o uguale a $t$ (ovvero $x_1 = -0.7$), da cui dividendo per $n = 5$ si ottiene $\nicefrac{1}{5}$;
        \item se $t \in \halfCloseInt{1.2, 1.6}$ allora $F_e(t) = \nicefrac{2}{5}$: due dati sono minori o uguali a $t$ (ovvero $-0.7$ e $1.2$), da cui dividendo per $n = 5$ si ottiene $\nicefrac{2}{5}$;
        \item se $t \in \halfCloseInt{1.6, 2.1}$ allora $F_e(t) = \nicefrac{3}{5}$;
        \item se $t \in \halfCloseInt{2.1, 3.4}$ allora $F_e(t) = \nicefrac{4}{5}$;
        \item se $t \geq 3.4$ allora $F_e(t) = 1$ (tutti i dati sono minori o uguali a $t$, dunque la percentuale è $1$);
    \end{itemize}

    Il grafico di questa funzione è quindi:
    \begin{center}
        \begin{tikzpicture}
            \begin{axis}[
                width=380pt,
                ylabel=$F_e(t)$,
                xlabel=$t$,
                ymin=-0.3,ymax=1.3,
                xmin=-3,xmax=5,
                xtick = {-0.7,1.2,1.6,2.1,3.4},
                xticklabels = {$-0.7$,$1.2$,$1.6$,$2.1$,$3.4$},
                ytick = {0,0.2,0.6,0.8,0.4,1},
                yticklabels = {$0$,$0.2$,$0.6$,$0.8$,$0.4$,$1$},
            ] 
            \addplot[cmhplot, domain=-3:-0.7]{0};
            \addplot[cmhplot, domain=-0.7:1.2]{0.2};
            \addplot[cmhplot, domain=1.2:1.6]{0.4};
            \addplot[cmhplot, domain=1.6:2.1]{0.6};
            \addplot[cmhplot, domain=2.1:3.4]{0.8};
            \addplot[cmhplot, domain=3.4:7]{1};
            \addplot[holdot]coordinates{(-0.7,0)(1.2,0.2)(1.6,0.4)(2.1,0.6)(3.4,0.8)};
            \addplot[soldot]coordinates{(-0.7,0.2)(1.2,0.4)(1.6,0.6)(2.1,0.8)(3.4,1)};

                % \addplot[blue,smooth] {1/(1+exp(-x))};
                % \addlegendentry{Logistic sigmoid}
            \end{axis}
            
        \end{tikzpicture}
    \end{center}
\end{example}

\subsubsection{Percentili e quantili}
\begin{definition}
    [Percentile] Sia $k \in \R$ con $0 \leq k \leq 100$. Allora, dato un vettore dei dati $\vec x$ il $k$-esimo percentile è un qualsiasi numero $t \in \R$ tale che \begin{itemize}
        \item almeno $\nicefrac{k}{100}$ dei dati sono minori o uguali di $t$,
        \item almeno $\nicefrac{1-k}{100}$ dei dati sono maggiori o uguali a $t$.
    \end{itemize}
\end{definition}
Intuitivamente un numero reale $t$ è il $k$-esimo percentile del nostro vettore di dati $\vec x$ se $t$ è il più piccolo numero che è maggiore o uguale al $k$ percento dei dati. Dato che preferiamo trattare numeri compresi tra $0$ e $1$ invece che tra $0$ e $100$ introduciamo il concetto di $\beta$-quantile: se $t$ è un $k$-esimo percentile, allora $t$ è un $\beta$-quantile per $\beta = \nicefrac{k}{100}$.

Detto più direttamente, un numero $t$ è un $\beta$-quantile se \begin{itemize}
    \item almeno $\beta$ dei dati sono minori o uguali a $t$,
    \item almeno $1-\beta$ dei dati sono maggiori o uguali a $t$.
\end{itemize}

\begin{example}
    Dato il vettore $\vec x = (10, 20, 40, 60, 100)$, il dato $x_4 = 60$ corrisponde all'$80$-esimo percentile, o equivalentemente allo $0.80$-quantile.
\end{example}

Alcuni quantili particolari hanno dei nomi specifici:
\begin{itemize}
    \item lo $0.25$-quantile è anche chiamato \emph{primo quartile},
    \item lo $0.50$-quantile è anche chiamato \emph{mediana},
    \item lo $0.75$-quantile è anche chiamato \emph{terzo quartile}.
\end{itemize}

\subsubsection{Dati multipli}
In alcuni casi è necessario fare indagini statistiche su dati multipli: rappresentiamo i nostri dati come un vettore di coppie (o triple, o $n$-uple) di dati: \[
    (\vec x, \vec y) = ((x_1, y_1), \dots, (x_n, y_n)).    
\] Per studiare la \emph{correlazione} tra i dati delle $x$ e i dati delle $y$ abbiamo bisogno di alcuni strumenti:
\begin{definition}
    [Covarianza] Dato un vettore di coppie di dati $(\vec x, \vec y)$ si dice \emph{covarianza campionaria} il numero \begin{equation}
        \cov{\vec x, \vec y} \deq \frac{1}{n-1}\sum_{i=1}^n (x_i - \mean x)(y_i - \mean y);
    \end{equation} si dice invece \emph{convarianza empirica} il numero \begin{equation}
        \cov*{\vec x, \vec y} \deq \frac{1}{n}\sum_{i=1}^n (x_i - \mean x)(y_i - \mean y).
    \end{equation}
\end{definition}

\begin{definition}
    [Coefficiente di correlazione] Dato un vettore di coppie di dati $(\vec x, \vec y)$, se $\sd{\vec x}, \sd{\vec y} \neq 0$, si dice \emph{coefficiente di correlazione} il numero \[
        r(\vec x, \vec y) \deq \frac{\cov{\vec x, \vec y}}{\sd{\vec x}\sd{\vec y}} = \frac{\displaystyle\sum_{i=1}^n (x_i - \mean x)(y_i - \mean y)}{\displaystyle\sqrt{\sum_{i=1}^n (x_i-\mean x)^2}\sqrt{\sum_{i=1}^n (y_i-\mean y)^2}}.
    \]
\end{definition}

\begin{proposition}
    Dato un vettore di coppie di dati $(\vec x, \vec y)$ con $\sd{\vec x}, \sd{\vec y} \neq 0$, vale che \[
            0 \leq \abs[\big]{r(\vec x, \vec y)} \leq 1.
    \]
\end{proposition}
\begin{proof}
    Viene dalla disuguaglianza di Cauchy-Schwartz: \[
        \sum_{i=1}^n \abs[\big]{(x_i - \mean x)(y_i - \mean y)} \leq \sqrt{\sum_{i=1}^n (x_i-\mean x)^2}\sqrt{\sum_{i=1}^n (y_i-\mean y)^2},   
    \] da cui segue che \[
        \abs[\big]{r(\vec x, \vec y)} = \frac{\displaystyle\sum_{i=1}^n \abs[\big]{(x_i - \mean x)(y_i - \mean y)}}{\displaystyle\sqrt{\sum_{i=1}^n (x_i-\mean x)^2}\sqrt{\sum_{i=1}^n (y_i-\mean y)^2}} \leq 1. \qedhere
    \]
\end{proof}

Intuitivamente il coefficiente di correlazione misura quanto è semplice approssimare la relazione tra le $x$ e le $y$ con una funzione lineare affine, ovvero con una retta: per vedere ciò cerchiamo di capire quale retta approssima meglio i nostri dati.

Per approssimare linearmente $(\vec x, \vec y)$ dobbiamo fare in modo che la nostra retta $a + bx$ sia il più vicino possibile ai punti $(x_i, y_i)$ che formano i dati: vogliamo quindi che per ogni punto $x_i$ la distanza tra $y_i$ e $a+bx_i$ sia la minima possibile. Possiamo ottenere quello che vogliamo calcolando il seguente valore: \begin{equation}
    \min_{a, b \in \R^2} \sum_{i=1}^n (y_i - a - bx_i)^2.   \label{eq:min_dist_retta} 
\end{equation} (Eleviamo le distanze al quadrato in modo da renderle tutte positive e le sommiamo insieme poiché vogliamo che la distanza \emph{complessiva} della retta sia minima.)

\begin{theorem}
    Il valore minimo della quantità in \eqref{eq:min_dist_retta} si ottiene scegliendo \[
        b^\ast = \frac{\cov{\vec x, \vec y}}{\var{\vec x}}, \quad a^\ast = -b\mean x + \mean y.    
    \] Inoltre vale che \[
        \min_{a, b \in \R^2} \sum_{i=1}^n (y_i - a - bx_i)^2 = \sum_{i= 1}^n (y_i - \mean y)^2\left( 1 - r(\vec x, \vec y)^2 \right).
    \]
\end{theorem}
\begin{proof}
    ["Dimostrazione"] Sia $Q : \R^2 \to \R$ la funzione definita da \[
        Q(a, b) \deq \sum_{i=1}^n (y_i - a - bx_i)^2.
    \] Per dimostrare che questa funzione ha minimo calcoliamo i limiti all'infinito: siccome vale che \[
        \lim_{\abs a, \abs b \to +\infty} \sum_{i=1}^n (y_i - a - bx_i)^2 = +\infty    
    \] per il teorema di Weierstrass generalizzato questa funzone ha minimo. Per calcolarlo, imponiamo che le derivate parziali $\dfrac{\partial Q}{\partial a}$ e $\dfrac{\partial Q}{\partial b}$ siano uguali a $0$, da cui ricaviamo le espressioni per $a^\ast$ e $b^\ast$. Sostituendole in $Q$ otteniamo l'espressione per il minimo di $Q$, che è la seconda parte della tesi.
\end{proof}

La retta $a^\ast + b^\ast x$ viene detta \emph{retta di regressione} ed è la funzione lineare affine che meglio approssima i dati che abbiamo a nostra disposizione. Dato che la minima distanza tra la retta e il vettore dei dati (nel senso dato dalla formulazione in \eqref{eq:min_dist_retta}) è proporzionale a $\left(1 - r(\vec x, \vec y)^2\right)$, avremo che: \begin{itemize}
    \item più $r(\vec x, \vec y)^2$ si avvicina a $1$, più la distanza minima si avvicina a $0$ e quindi i dati sono correlati linearmente;
    \item più $r(\vec x, \vec y)^2$ si avvicina a $0$, più la distanza minima cresce e quindi i dati sono dispersi e non seguono una correlazione lineare.
\end{itemize}
Inoltre il coefficiente angolare della retta di regressione $b^\ast$ può essere riscritto come \[
    b^\ast = \frac{\cov{\vec x, \vec y}}{\var{\vec x}} = \frac{\cov{\vec x, \vec y}}{\sd{\vec x}\sd{\vec y}}\frac{\sd{\vec x}\sd{\vec y}}{\var{\vec x}} = r(\vec x, \vec y)\frac{\sd{\vec x}\sd{\vec y}}{\var{\vec x}}.
\] Dato che $\frac{\sd{\vec x}\sd{\vec y}}{\var{\vec x}} \geq 0$ il segno del coefficiente angolare dipende solamente dal coefficiente di correlazione: \begin{itemize}
    \item se $r(\vec x, \vec y) > 0$ la retta di regressione ha coefficiente angolare positivo, dunque è crescente e al crescere delle $x$ tendenzialmente crescono anche le $y$;
    \item se $r(\vec x, \vec y) < 0$ la retta di regressione ha coefficiente angolare negativo, dunque è decrescente e al crescere delle $x$ tendenzialmente le $y$ decrescono.
\end{itemize}

Il coefficiente di correlazione dunque ci dice quanto sono correlate le due quantità che stiamo esaminando (più è vicino ad $1$ e più sono correlate) e se al crescere della prima cresce anche la seconda (se è di segno positivo), oppure al crescere della prima la seconda diminuisce (se è di segno negativo).