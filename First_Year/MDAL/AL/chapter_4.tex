
\chapter{Determinanti}

\section{Definizione e significato del determinante}

\begin{definition}
    Sia $A$ una matrice quadrata $n \times n$ e siano $\vec{C_1}, \dots, \vec{C_n} \in \R^n$ le sue colonne. Allora si dice determinante una funzione \[
        \det : \M_{n \times n}(\R) \to \R 
    \] che rispetta le seguenti proprieta':

    \begin{enumerate}[(i)]
        \item $\det I_n = 1$, cioe' il determinante della matrice identita' $n \times n$ deve essere 1;
        \item se per qualche $i, j$ compresi tra $1$ e $n$, con $i \neq j$, vale che $\vec{C_i} = \vec{C_j}$, allora $\det A = 0$, cioe' se due colonne della matrice sono uguali il determinante deve essere 0;
        \item se $A'$ e' la matrice ottenuta moltiplicando una colonna della matrice $A$ per $\lambda \in \R$, cioe' $A' = \begin{pmatrix} \vec{C_1} & \dots & \lambda \vec{C_i} & \dots & \vec{C_n} \end{pmatrix}$ allora \[\det A' = \lambda \det A;\]
        \item se la colonna $\vec{C_i}$ e' esprimibile come $\vec{v_1} + \vec{v_2}$ con $\vec{v_1}, \vec{v_2} \in \R^n$, cioe' $A = \begin{pmatrix} \vec{C_1} & \dots & \vec{v_1} + \vec{v_2} & \dots & \vec{C_n} \end{pmatrix}$
        allora \[
            \det A = \det \begin{pmatrix} \vec{C_1} & \dots & \vec{v_1} & \dots & \vec{C_n} \end{pmatrix} + \det \begin{pmatrix} \vec{C_1} & \dots & \vec{v_2} & \dots & \vec{C_n} \end{pmatrix} 
        \] cioe' il determinante e' lineare nelle colonne della matrice.
    \end{enumerate}
\end{definition}

Il determinante di una matrice si indica anche con \[
    \det A = \abs{A}.    
\]

Possiamo anche definire il determinante come una funzione che prende esattamente $n$ vettori di $\R^n$ e restituisce un numero reale, cioe' $\det : (\R^n)^n \to \R$ e che rispetta le seguenti proprieta':
\begin{enumerate}
    [(i)]
    \item se $\vec{c_1}, \dots, \vec{c_n}$ sono i vettori della base standard di $\R^n$, allora \[\det(\vec{c_1}, \dots, \vec{c_n}) = 1;\]
    \item $\det(\vec{v_1}, \dots, \vec{v_i}, \dots, \vec{v_i}, \dots, \vec{v_n}) = 0$, cioe' se due dei vettori sono uguali allora il determinante e' nullo;
    \item $\det(\vec{v_1}, \dots, \lambda\vec{v_i}, \dots, \vec{v_n}) = \lambda \det (\vec{v_1}, \dots, \vec{v_i}, \dots, \vec{v_n})$;
    \item le somme escono fuori dal determinante, cioe' \begin{alignat*}{1}
        &\det(\vec{v_1}, \dots, \vec{v_i} + \vec{w}, \dots, \vec{v_n})\\
        = &\det (\vec{v_1}, \dots, \vec{v_i}, \dots, \vec{v_n}) + \det (\vec{v_1}, \dots, \vec{w}, \dots, \vec{v_n}).
    \end{alignat*}
\end{enumerate}

Dalle quattro proprieta' base ne discendono altre, che elenchiamo in questa proposizione:
\begin{proposition}
    Il determinante ha le seguenti proprieta':
    \begin{enumerate}
        [(i)]
        \item se scambio due colonne della matrice tra loro il determinante cambia segno;
        \item le combinazioni lineari escono fuori dal determinante;
        \item se una delle $n$ colonne e' combinazione lineare delle restanti, cioe' se gli $n$ vettori formano un insieme di vettori linearmente dipendenti, allora il determinante e' uguale a $0$;
        \item sommando ad una colonna un multiplo di un'altra colonna il determinante non cambia;
        \item il determinante di una matrice e' uguale al determinante della trasposta.
    \end{enumerate}
\end{proposition}

Notiamo che la mossa principale di Gauss-Jordan, cioe' sommare ad una colonna un multiplo di un'altra colonna, non modifica il determinante di una matrice: possiamo calcolare i determinanti quindi tramite mosse di Gauss-Jordan, facendo attenzione a cambiare il segno se scambiamo due colonne o a portare fuori i fattori per cui moltiplichiamo le colonne.

Dall'ultima proprieta' segue che ogni proprieta' che si basa sulle colonne puo' anche essere riformulata in termini delle righe della matrice (che corrispondono alle colonne della trasposta).

Dalle proprieta' precedenti segue che il determinante di una matrice e' $0$ se e solo se ci sono due colonne linearmente dipendenti: dunque il determinante e' una funzione che indica la dipendenza lineare tra i vettori a cui viene applicato.

\subsection{Determinante di matrici particolari}

\subsubsection{Determinante di matrici diagonali}

Consideriamo la matrice diagonale \[
    D = \begin{pmatrix}
        \lambda_1   &0          &\dots  &0 \\
        0           &\lambda_2  &\dots  &0 \\
        \vdots      &\vdots     &\ddots &\vdots \\
        0           &0          &\dots  &\lambda_n \\
    \end{pmatrix}.    
\] Applicando il terzo assioma possiamo estrarre i coefficienti di ogni colonna, ottenendo
\begin{alignat*}{1}
    \det \begin{pmatrix}
        \lambda_1   &0          &\dots  &0 \\
        0           &\lambda_2  &\dots  &0 \\
        \vdots      &\vdots     &\ddots &\vdots \\
        0           &0          &\dots  &\lambda_n \\
    \end{pmatrix} = &\lambda_1 \det \begin{pmatrix}
        1           &0          &\dots  &0 \\
        0           &\lambda_2  &\dots  &0 \\
        \vdots      &\vdots     &\ddots &\vdots \\
        0           &0          &\dots  &\lambda_n \\
    \end{pmatrix} \\
    = &\lambda_1 \lambda_2 \det \begin{pmatrix}
        1           &0          &\dots  &0 \\
        0           &1          &\dots  &0 \\
        \vdots      &\vdots     &\ddots &\vdots \\
        0           &0          &\dots  &\lambda_n \\
    \end{pmatrix} \\
    \intertext{Ripetendo il procedimento per ogni colonna arriviamo a}
    = &\lambda_1 \lambda_2 \dots \lambda_n \det I_n \\
    = &\lambda_1 \lambda_2 \dots \lambda_n.
\end{alignat*}
Dunque il determinante di una matrice diagonale e' il prodotto degli elementi sulla diagonale principale.

\subsubsection{Determinante di matrici triangolari superiori o inferiori}

Consideriamo una matrice triangolare superiore (o inferiore), cioe' una matrice che ha tutti zeri sotto (o sopra) la diagonale principale. Tramite mosse di Gauss-Jordan possiamo trasformare questa matrice in una matrice diagonale senza dover scambiare colonne tra di loro, dunque il determinante della matrice triangolare e' uguale al determinante della matrice diagonale, cioe' e' il prodotto degli elementi sulla sua diagonale principale.

\begin{equation*}
    \det \begin{pmatrix}
        \lambda_1   &\star      &\dots  &\star \\
        0           &\lambda_2  &\dots  &\star \\
        \vdots      &\vdots     &\ddots &\vdots \\
        0           &0          &\dots  &\lambda_n \\
    \end{pmatrix} = \det \begin{pmatrix}
        \lambda_1   &0          &\dots  &0 \\
        \star       &\lambda_2  &\dots  &0 \\
        \vdots      &\vdots     &\ddots &\vdots \\
        \star       &\star      &\dots  &\lambda_n \\
    \end{pmatrix} = \lambda_1 \lambda_2 \dots \lambda_n
\end{equation*}
dove $\star$ indica un qualsiasi numero reale.

\subsubsection{Determinante di matrici $2 \times 2$}

Consideriamo una matrice $A \in \M_{2 \times 2}(\R)$ generica e calcoliamone il determinante. Se $a \neq 0$ allora \begin{equation*}
    \det \begin{pmatrix} a & b \\ c & d \end{pmatrix} = \det \begin{pmatrix} a & b \\ 0 & d - \frac{c}{a}b \end{pmatrix} = ad - bc.
\end{equation*}
Se $a = 0$ allora \begin{equation*}
\det \begin{pmatrix} 0 & b \\ c & d \end{pmatrix} = -\det \begin{pmatrix} b & 0 \\ d & c \end{pmatrix} = -bc = 0d - bc = ad - bc.
\end{equation*}
Dunque il determinante di $\begin{psmallmatrix} a & b \\ c & d \end{psmallmatrix}$ e' $ad - bc$.

Il determinante di una matrice $2 \times 2$ e' l'area del parallelogramma che ha come lati i vettori che formano le colonne della matrice. Notiamo infatti che se i due vettori sono sulla stessa retta, cioe' se sono dipendenti, allora l'area del parallelogramma e' 0, esattamente come il determinante.

\subsubsection{Determinante di matrici $3 \times 3$}

Per calcolare il determinante di una matrice $A \in \M_{3 \times 3}(\R)$ generica possiamo usare la regola di Sarrus: creiamo una matrice $3 \times 5$ dove le ultime due colonne sono le prime due ripetute. Il determinante sara' allora la somma dei prodotti delle prime tre diagonali da sinistra verso destra meno il prodotto delle tre diagonali da destra verso sinistra.
Dunque se \[
    A = \begin{pmatrix}
        a & b & c \\
        d & e & f \\
        g & h & i \\
    \end{pmatrix}
\] consideriamo la matrice \[
    A = \begin{pmatrix}[ccc|cc]
        a & b & c & a & b \\
        d & e & f & d & e\\
        g & h & i & g & h\\
    \end{pmatrix}
\] e otteniamo che \[
    \det A = aei + bfg + cdh - bdi - afh - ceg.    
\]

Il determinante di una matrice $3 \times 3$ e' il volume del "parallelepipedo" che ha come lati i vettori che formano le colonne della matrice: infatti se un vettore e' nello span degli altri due allora il volume viene 0.

\section{Sviluppi di Laplace}

\begin{definition}
    Sia $A \in \M_{n\times m}(\R)$. Allora diciamo che $B$ e' una sottomatrice di $A$ se $B \in \M_{(n-k) \times (m-h)}(\R)$ e $B$ si ottiene eliminando $k$ righe e $h$ colonne di $A$.
\end{definition}

\begin{definition}
    Sia $A \in \M_{n\times m}(\R)$. Allora diciamo che $B$ e' un minore di $A$ se e' una sottomatrice quadrata di $A$.
\end{definition}

Possiamo quindi enunciare il metodo degli sviluppi di Laplace per calcolare il determinante di una matrice.

\begin{theorem}
    [Sviluppi di Laplace]
    Sia $A \in \M_{n \times n}(\R)$ una matrice quadrata. 
    
    Sia $C_j = \begin{pmatrix}
        a_{1j} & \dots & a_{nj}
    \end{pmatrix}^T$ una colonna qualsiasi di $A$. 
    
    Chiamo $M_{ij}$ il minore di $A$ ottenuto eliminando la riga $i$-esima e la colonna $j$-esima. Inoltre per ogni $i$ compreso tra 1 e $n$ chiamo cofattore $c_{ij}$ la quantita' \[
        c_{ij} = (-1)^{i+j} \det M_{ij}.
    \]
    Allora vale che \begin{equation}
        \det A = a_{1j}c_{1j} + \dots + a_{nj}c_{nj} = \sum_{i = 1}^n a_{ij}c_{ij}.
    \end{equation}
\end{theorem}

Il metodo funziona anche scegliendo una colonna invece di una riga.

\begin{example}
    Trovare il determinante di \[
    A = \begin{pmatrix}
        2 & 1 & 0 \\ 3 & 2 & 1 \\ 3 & 3 & 1
    \end{pmatrix}    
    \] tramite sviluppi di Laplace.
\end{example}
\begin{solution}
    Scegliamo come colonna la prima colonna.
    Allora \begin{alignat*}
        {1}
        \det A &= a_{13}(-1)^{1+3} \begin{vmatrix}  3 & 2 \\ 3 & 3 \end{vmatrix} + a_{23}(-1)^{2+3} \begin{vmatrix}  2 & 1 \\ 3 & 3 \end{vmatrix} + a_{33}(-1)^{3+3} \begin{vmatrix}  3 & 2 \\ 2 & 1 \end{vmatrix}\\
            &= -\begin{vmatrix}  2 & 1 \\ 3 & 3 \end{vmatrix} + \begin{vmatrix} 3 & 2 \\ 2 & 1 \end{vmatrix} \\
            &= -(2 \cdot 3 - 1 \cdot 3) + (2 \cdot 2 - 1 \cdot 3)\\
            &= -3 + 6 + 4 - 3\\
            &= 4.
    \end{alignat*}
\end{solution}

\section{Rango e determinanti}

Diamo ora la definizione esatta di rango di una matrice.

\begin{definition}
    Sia $A \in \M_{n \times m}(\R)$ e sia $L_A : \R^m \to \R^n$ l'applicazione lineare associata alla matrice $A$. Allora si dice rango della matrice $A$ la dimensione dell'immagine dell'applicazione lineare associata, cioe'
    \begin{equation}
        \rk{A} = \dim \Imm{L_A}
    \end{equation}
\end{definition}

\begin{proposition}
    Sia $A \in \M_{n \times m}(\R)$. Siano $R_1, \dots, R_n \in \R^m$ le righe di $A$ e $C_1, \dots, C_m \in \R^n$ le colonne di $A$. Sia inoltre $L_A : \R^m \to \R^n$ l'applicazione lineare associata alla matrice $A$.
    
    Allora i seguenti fatti sono equivalenti:
    \begin{itemize}
        \item $k = \rk{A}$
        \item $k = \dim \Span{C_1, \dots, C_m}$;
        \item $k = \dim \Span{R_1, \dots, R_n}$;
        \item $k$ e' il numero di pivot della matrice a scalini $A'$ ottenuta tramite mosse di Gauss a partire dalla matrice $A$;
    \end{itemize}
\end{proposition}
\begin{proof}
    Se $k$ e' il rango della matrice, allora per definizione di rango $k = \dim \Imm{L_A}$. Per la proposizione \ref{span_colonne=immagine_applicazione_associata} lo span delle colonne della matrice e' uguale all'immagine dell'applicazione lineare associata, dunque $k = \dim \Span{C_1, \dots, C_m}$.

    Supponiamo che la matrice sia a scalini per colonne. Allora le colonne indipendenti sono tutte e solo le colonne con i pivot, mentre le altre colonne sono nulle. Dato che le colonne con i pivot formano una base dell'immagine, segue che devono esserci esattamente $k = \rk{A}$ colonne indipendenti, e quindi $k$ pivot. 
    Inoltre le righe indipendenti sono quelle con i pivot, dunque devono esserci anche $k$ righe indipendenti, cioe' $\dim \Span{R_1, \dots, R_n} = k$.

    Supponiamo che la matrice non sia a scalini per colonne. Allora riduciamola a scalini per colonne tramite mosse di Gauss, ottenendo la matrice $A'$ che ha per colonne i vettori $C'_1, \dots, C'_m$ e per righe i vettori $R'_1, \dots, R'_n$.
    Per la proposizione \ref{span_colonne_indipendenti} segue che $\Span{C'_1, \dots, C'_m} = \Span{C_1, \dots, C_m}$, dunque anche le loro dimensioni saranno uguali. Dato che la dimensione di $\Span{C'_1, \dots, C'_m}$ e' data dal numero di colonne indipendenti, cioe' dal numero di pivot per colonna, abbiamo dimostrato che il numero di pivot e' uguale alla dimensione di $\Span{C_1, \dots, C_m}$, cioe' al rango di $A$. Infine per la proposizione \ref{invarianza_dim_righe_per_mosse_colonna} ridurre una matrice a scalini per colonne non cambia la dimensione delle righe, dunque dato che la dimensione di $\Span{R'_1, \dots, R'_n}$ e' uguale al numero di pivot (cioe' $k$), allora anche la dimensione di $\Span{R_1, \dots, R_n}$ dovra' essere uguale a $k$.
\end{proof}

\begin{proposition}
    Sia $A \in \M_{n \times n}(\R)$ e sia $L_A : \R^n \to \R^n$ l'applicazione lineare associata ad $A$. Allora $L_A$ e' bigettiva se e solo se $\rk{A} = n$.
\end{proposition}
\begin{proof}
    Dire che $L_A$ e' bigettiva equivale a dire che per ogni $\vec b \in \R^n$ esiste uno e un solo vettore $\vec x$ tale che $L_A(\vec x) = \vec b$, cioe' che il sistema $A\vec x = \vec b$ ha una e una sola soluzione.

    Per la proposizione \ref{sistema_quadrato_n_pivot_unica_soluzione} questo avviene se e solo se il sistema ridotto a scalini ha $n$ pivot, cioe' $\rk{A} = n$. 
\end{proof}

Ora iniziamo ad analizzare la relazione tra determinanti e rango di una matrice.

\begin{theorem}\label{det_nonnullo_sse_rango_n}
    Sia $A \in \M_{n \times n}(\R)$. 
    
    Allora $\det A \neq 0$ se e solo se $\rk{A} = n$.
\end{theorem}
\begin{proof}
    Riduciamo $A$ a scalini tramite mosse di Gauss, senza moltiplicare le righe per coefficienti. La matrice ottenuta tramite questo processo, chiamiamola $S$, dovra' avere lo stesso determinante di $A$ a meno del segno: \[
        \abs{\det A} = \abs{\det S}.
    \] Dunque $\det A \neq 0$ se e solo se $\det S \neq 0$. 
    
    Dato che $S$ e' quadrata e a scalini segue che $S$ dovra' essere triangolare superiore, dunque il determinante di $S$ e' il prodotto degli elementi sulla diagonale principale, cioe' dei pivot di $S$.
    
    Dunque il determinante di $S$ e' diverso da $0$ se e solo se $S$ ha $n$ pivot, cioe' $\rk{S} = n$. Dato che le mosse di Gauss non cambiano il rango di una matrice, segue che $\det A \neq 0$ se e solo se $\rk{A} = n$, che e' la tesi.
\end{proof}

\begin{proposition}\label{rango_geq_k_sse_det_minore_k_neq_0}
    Sia $A \in \M_{n \times n}(\R)$.
    
    Allora $\rk{A} \geq k$ se e solo se esiste un minore $M_k$ di dimensione $k \times k$ tale che $\det M_k \neq 0$.
\end{proposition}
\begin{proof} Dimostriamo l'implicazione nei due versi.
    \begin{description}
        \item[($\implies$).] Dato che $\rk{A} \geq k$ dovranno esserci almeno $k$ righe e $k$ colonne indipendenti. 
        
        Scelgo $k$ righe indipendenti e elimino le altre, ottenendo una sottomatrice $S$ di dimensione $k \times n$ tale che $\rk{S} = k$. Dato che il rango e' anche il numero di colonne linearmente indipendenti, allora questa sottomatrice avra' anche almeno $k$ colonne linearmente indipendenti, dunque ne scelgo $k$ e elimino le altre.

        A questo punto ho ottenuto una sottomatrice $k \times k$ di $A$ con rango uguale a $k$, che e' la tesi.
        \item[($\impliedby$).] Per la proposizione \ref{det_nonnullo_sse_rango_n} segue che $\rk{B} = k$, dunque $B$ ha $k$ righe indipendenti. Consideriamo le relative $k$ righe di $A$: allora anche esse devono essere indipendenti, in quanto per annullare le prime $k$ componenti e' necessario che i coefficienti della combinazione lineare siano tutti uguali a $0$. Dunque $A$ ha almeno $k$ righe indipendenti, dunque $\rk{A} \geq k$. \qedhere
    \end{description}
\end{proof}

\begin{proposition}\label{rango_tramite_minori}
    Sia $A \in \M_{n \times n}(\R)$.
    Allora $\rk{A} = k$ se e solo se \begin{enumerate}[(i)]
        \item esiste almeno un minore $M_k$ di dimensione $k \times k$ tale che $\det M_k \neq 0$;
        \item per ogni minore $M_{k+1}$ di dimensione $(k + 1) \times (k + 1)$ vale che $\det M_{k+1} = 0$.
    \end{enumerate} 
\end{proposition}
\begin{proof}
    Dimostriamo l'implicazione nei due versi.
    \begin{description}
        \item[($\implies$).] Dato che $\rk{A} = k$ segue che $\rk{A} \geq k$, dunque per la proposizione precedente (\ref{rango_geq_k_sse_det_minore_k_neq_0}) esiste un minore di dimensione $k \times k$ con $\det M_k \neq 0$. 
        
        Dato che $\rk{A} = k$ segue che $\rk{A} < k+1$, dunque per la stessa proposizione non puo' esistere un minore di dimensione $(k+1) \times (k+1)$ con determinante diverso da $0$, cioe' $\det M_{k+1} = 0$ per ogni minore $M_{k+1}$ di dimensione $(k+1) \times (k+1)$.
        \item[($\impliedby$).] Per la proposizione precedente (\ref{rango_geq_k_sse_det_minore_k_neq_0}), dato che esiste almeno un minore con determinante non nullo di dimensione $k \times k$, allora $\rk{A} \geq k$. 
        
        Per la stessa proposizione, dato che non esistono minori di dimensioni $(k+1) \times (k+1)$ con determinante non nullo, segue che $\rk{A} < k+1$, che e' equivalente a $\rk{A} \leq k$.
        
        Dunque $\rk{A} = k$. \qedhere
    \end{description}
\end{proof}

Il seguente teorema riassume le varie definizioni di rango.

\begin{theorem}\label{equivalenza_definizioni_di_rango}
    Sia $A \in \M_{n \times m}(\R)$ e sia $L_A : \R^m \to \R^n$ l'applicazione lineare associata alla matrice $A$. Siano inoltre $R_1, \dots, R_n \in \R^m$ le righe di $A$ e $C_1, \dots, C_m \in \R^n$ le colonne di $A$. 
    
    Allora i seguenti fatti sono equivalenti:
    \begin{enumerate}
        [(i)]
        \item $k = \rk{A} = \dim \Imm L_A$;
        \item $k = \dim \Span{R_1, \dots, R_n}$, cioe' $k$ e' il numero di righe indipendenti di $A$;
        \item $k = \dim \Span{C_1, \dots, C_m}$, cioe' $k$ e' il numero di colonne indipendenti di $A$;
        \item $k$ e' il numero di pivot della matrice $S$ ottenuta riducendo a scalini la matrice $A$;
        \item $k$ e' il massimo numero tale che esiste $M_k \in \M_{k \times k}(\R)$ tale che $M_k$ e' un minore di $A$ con $\det M_k \neq 0$.
    \end{enumerate}
\end{theorem}

Il seguente teorema invece riassume le relazioni tra rango e determinante.

\begin{theorem}\label{relazioni_determinante_rango}
    Sia $A \in \M_{n \times n}(\R)$ e sia $L_A : \R^n \to \R^n$ l'applicazione lineare associata alla matrice $A$. Siano inoltre $R_1, \dots, R_n \in \R^n$ le righe di $A$ e $C_1, \dots, C_n \in \R^n$ le colonne di $A$. 
    
    Allora i seguenti fatti sono equivalenti:
    \begin{enumerate}
        [(i)]
        \item $\det A \neq 0$;
        \item $\rk{A} = n$;
        \item $L_A$ e' bigettiva (ovvero $\Imm L_A = \R^n$ e $\ker L_A = \{\vec 0\}$);
        \item $A$ e' invertibile;
        \item le righe di $A$ sono indipendenti, ovvero $\dim \Span{R_1, \dots, R_n} = n$;
        \item le colonne di $A$ sono indipendenti, ovvero $\dim \Span{C_1, \dots, C_n} = n$.
    \end{enumerate}
\end{theorem}